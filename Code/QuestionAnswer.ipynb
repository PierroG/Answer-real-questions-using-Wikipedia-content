{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "import wikipedia\n",
    "import nltk\n",
    "#utile pour le pos tagging\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Model function\n",
    "Use loaded BERT model to return answer<br>\n",
    "**Input** : Question, Context text <br>\n",
    "**return** : Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question, answer_text):\n",
    "    print(\"I'm looking for an aswer, wait please ...\")\n",
    "    # == Tokenize ==\n",
    "    # use a python dictonary so run on CPU\n",
    "    # Apply the tokenizer to the input text, treating them as a text-pair.\n",
    "    print(\"-Tokenization\")\n",
    "    input_ids = tokenizer.encode(question, answer_text)\n",
    "    #print('The input has a total of {:} tokens.'.format(len(input_ids)))\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    # == Set Segment IDs ==\n",
    "    # Search the input_ids for the first instance of the `[SEP]` token.\n",
    "    sep_index = input_ids.index(tokenizer.sep_token_id)\n",
    "\n",
    "    # The number of segment A tokens includes the [SEP] token istelf.\n",
    "    num_seg_a = sep_index + 1\n",
    "\n",
    "    # The remainder are segment B.\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "\n",
    "    # Construct the list of 0s and 1s.\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "\n",
    "    # There should be a segment_id for every input token.\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "\n",
    "    # == Run Model ==\n",
    "    # Run our example through the model.\n",
    "    # by default on CPU, use model.to(device) to select GPU !?\n",
    "    print(\"-Forward pass on the model\")\n",
    "    start_scores, end_scores = model(torch.tensor([input_ids]), # The tokens representing our input text.\n",
    "                                 token_type_ids=torch.tensor([segment_ids])) # The segment IDs to differentiate question from \n",
    "\n",
    "    \n",
    "    # donc on applique un argmax pour trouver le plus probable\n",
    "    # Find the tokens with the highest `start` and `end` scores.\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "    \n",
    "    print(type(start_scores))\n",
    "    print(start_scores.size())\n",
    "    print(start_scores[0,answer_start])\n",
    "    print(end_scores[0,answer_end])\n",
    "    \n",
    "    # == Print Answer without ## ==\n",
    "    # Start with the first token.\n",
    "    answer = tokens[answer_start]\n",
    "\n",
    "    # Select the remaining answer tokens and join them with whitespace.\n",
    "    for i in range(answer_start + 1, answer_end + 1):\n",
    "    \n",
    "        # If it's a subword token, then recombine it with the previous token.\n",
    "        if tokens[i][0:2] == '##':\n",
    "            answer += tokens[i][2:]\n",
    "    \n",
    "        # Otherwise, add a space then the token.\n",
    "        else:\n",
    "            answer += ' ' + tokens[i]\n",
    "\n",
    "    return answer\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "### Question Processing\n",
    "Extract subjet _(and more?)_ from the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_subject(question):\n",
    "    subject = None\n",
    "    token = nltk.word_tokenize(question)\n",
    "    #print(token)\n",
    "    pos_token = nltk.pos_tag(token)\n",
    "    for item in pos_token:\n",
    "        if item[1] == 'NN':\n",
    "            subject = item[0]\n",
    "    if subject is not None:\n",
    "        print(\"Subject found: \" + subject)\n",
    "    else:\n",
    "        print(\"Subject not found üòî\\n Rephrase the question or try another one\")\n",
    "    return  subject\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject found: my cat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'my cat'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_subject_with_spacy(question):\n",
    "    #noun to not take in count\n",
    "    osef_list = ['who','why','what','when','which','how']\n",
    "    doc = nlp(question)\n",
    "    nouns = doc.noun_chunks\n",
    "    #print(len(list(nouns)))\n",
    "    for item in nouns:\n",
    "        if str(item) not in osef_list:\n",
    "            print(\"Subject found: \" + str(item))\n",
    "            return str(item)\n",
    "    print(\"Subject not found üòî\\n Rephrase the question or try another one\")\n",
    "        \n",
    "#test\n",
    "extract_subject_with_spacy('my cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikipedia API\n",
    "Try to found the most relevant context text to give as BERT input. <br>\n",
    "Get a wikipedia article, and scrap it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# == WIP ==\n",
    "# d√©coup√© en paragraphe (le model a une limite de 512 token pour le text en entr√©)\n",
    "def get_wiki_and_split(subject):\n",
    "    text = wikipedia.summary(subject)\n",
    "    print(len(text))\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salsa',\n",
       " 'Salsa (dance)',\n",
       " 'Salsa music',\n",
       " 'Salsa (sauce)',\n",
       " 'Bad Salsa',\n",
       " 'Pico de gallo',\n",
       " 'Salsa Lizano',\n",
       " 'Electrica Salsa',\n",
       " 'Salsa verde',\n",
       " 'Salsa roja']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikipedia.search(\"salsa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Samba (Portuguese pronunciation: [Ààs…êÃÉb…ê] (listen)), also known as samba urbano carioca (Urban Carioca Samba) or simply samba carioca (Carioca Samba) is a Brazilian music genre that originated in the Afro-Brazilians communities of Rio de Janeiro in the early 20th century', ' Having its roots in the cultural expression of West Africa and in Brazilian folk traditions, especially those linked to the primitive rural samba of the colonial and imperial periods, is considered one of the most important cultural phenomena in Brazil and one of the country symbols Present in the Portuguese language at least since the 19th century, the word ‚Äúsamba‚Äù was originally used to designate a ‚Äúpopular dance‚Äù', ' Over time, its meaning has been extended to a ‚Äúbatuque-like circle dance‚Äù, a dance style and also to a ‚Äúmusic genre‚Äù', ' This process of establishing itself as a musical genre began in the 1910s and it had its inaugural landmark in the song ‚ÄúPelo Telefone‚Äù, launched in 1917', ' Despite being identified by its creators, the public and the Brazilian music industry as ‚Äúsamba‚Äù, this pioneering style was much more connected from the rhythmic and instrumental point of view to maxixe than to samba itself', 'Samba was modernly structured as a musical genre only in the late 1920s from the neighborhood of Est√°cio and soon extended to Oswaldo Cruz and other parts of Rio through its commuter rail', ' Today synonymous with the rhythm of samba, this new samba brought innovations in rhythm, melody and also in thematic aspects', ' Its rhythmic change based on a new percussive instrumental pattern resulted in a more ‚Äúbatucado‚Äù and syncopated style ‚Äì as opposed to the inaugural ‚Äúsamba-maxixe‚Äù ‚Äì notably characterized by a faster tempo, longer notes and a characterized cadence far beyond the simple ones palms used so far', ' Also the ‚ÄúEst√°cio paradigm‚Äù innovated in the formatting of samba as a song, with its musical organization in first and second parts in both melody and lyrics', ' In this way, the sambistas of Est√°cio created, structured and redefined the Urban Carioca Samba as a genre in a modern and finished way', ' In this process of establishment as an urban and modern musical expression, the Carioca Samba had the decisive role of samba schools, responsible for defining and legitimizing definitively the aesthetic bases of rhythm, and radio broadcasting, which greatly contributed to the diffusion and popularization of the genre and its song singers', ' Thus, samba has achieved major projection throughout Brazil and has become one of the main symbols of Brazilian national identity', \" Once criminalized and viewed with prejudice for its Afro-Brazilian origins, the genre has also conquered support between members of the most favored classes and the country's cultural elite\", 'At the same time that it established itself as the genesis of samba, the ‚ÄúEst√°cio paradigm‚Äù paved the way for its fragmentation into new sub-genres and styles of composition and interpretation throughout the 20th century', ' Mainly from the so-called ‚Äúgolden age‚Äù of Brazilian music, samba received abundant categorizations, some of which denote solid and well-accepted derivative strands ‚Äì such as bossa nova, pagode, partido alto, samba de breque, samba-can√ß√£o, samba de enredo and samba de terreiro ‚Äì while other nomenclatures were somewhat more imprecise ‚Äì such as samba do barulho (literally ‚Äúnoise samba‚Äù), samba epistolar (‚Äúepistolary samba‚Äù) ou samba fon√©tico (‚Äúphonetic samba‚Äù) ‚Äì and some merely derogatory ‚Äì such as sambalada, sambolero or samb√£o joia', 'The modern samba that emerged at the beginning of the 20th century is predominantly in a 2/4 time signature varied with the conscious use of a sung chorus to a batucada rhythm, with various stanzas of declaratory verses', ' Its traditional instrumentation is composed of percussion instruments such as the pandeiro, cu√≠ca, tamborim, ganz√° and surdo accompaniment ‚Äì whose inspiration is choro ‚Äì such as classical guitar and cavaquinho', ' In 2007, the Brazilian National Institute of Historic and Artistic Heritage declared Carioca Samba and three of its matrixes ‚Äì samba de terreiro, partido-alto and samba de enredo ‚Äì as cultural heritage in Brazil', '']\n"
     ]
    }
   ],
   "source": [
    "text = wikipedia.summary('salsa')\n",
    "list = text.split('.')\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0850aee15a3d4884b3cd8b225fd69aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(height='0px', margin='100px 0 0 100px', width='400px')), Button(de‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f93ef905d24633a8dce6a0e42722bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='auto', margin='50px 0 100px 100px', width='450px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from ipywidgets import widgets\n",
    "\n",
    "#Widgets layout difinition\n",
    "layout = widgets.Layout(width='400px', height='0px', margin='100px 0 0 100px')\n",
    "bLayout = widgets.Layout(width='50px', height='28px', margin='100px 0 0 0px')\n",
    "outLayoutPropre = widgets.Layout(width='480px', height='100px', margin='50px 0 100px 100px')\n",
    "outLayoutTest = widgets.Layout(width='450px', height='auto', margin='50px 0 100px 100px')\n",
    "#titleLayout = widgets.Layout(width='450px', height='auto', margin='0px 0 0px 100px')\n",
    " \n",
    "#Widgets object definition\n",
    "text = widgets.Text(layout=layout)\n",
    "button = widgets.Button(description = 'Ask', layout = bLayout)\n",
    "out = widgets.Output(layout=outLayoutTest)#layout=outLayout\n",
    "#out = widgets.HTML(layout = outLayout, value= '<style>.text {width: 480px; heigh: 100px;}</style> <p class=\"text\">'+ out_value +' </p>')\n",
    " \n",
    "def button_on_click(self):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        subject = extract_subject_with_spacy(question=text.value)\n",
    "        if subject is not None:\n",
    "            context = wikipedia.summary(subject)\n",
    "            \n",
    "            answer = generate_answer(text.value, context[:2000])\n",
    "            #out.clear_output()\n",
    "            print(\"Here what i found: \\n\"+ answer)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "button.on_click(button_on_click)\n",
    "\n",
    "display(widgets.HBox((text, button,)))\n",
    "display(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
